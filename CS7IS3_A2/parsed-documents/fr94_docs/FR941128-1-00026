FR941128-1-00026 FR941128-1-00005 To examine the sensitivity of the design concentrations across a range of source characteristics, scenarios considering source size, elevation, and downwind distance were simulated. 14 For each scenario, the high-second high (HSH) 1-hour, 3-hour, 24-hour averages and high annual averages were determined using a full year of meteorological data; both rural and urban mode dispersion options were used. Generally, the concentration ratio 15 averaged ~ ¢ 1.2 (1-hour) to ~ ¢ 1.0 (annual). However, for receptors located within and nearby the area source, the ratio averaged ~ ¢ 2 (1-hour) to ~ ¢ 3 (annual). Thus, for receptors inside the area source, the ratio is higher than for receptors outside the source, where the effect is a function of averaging time and proximity to the source in question. 14 Environmental Protection Agency, 1992. Sensitivity Analysis of a Revised Area Source Algorithm for the Industrial Source Complex Short Term Model. EPA Publication No. EPA&hyph;454/R&hyph;92&hyph;015. U.S. Environmental Protection Agency, Research Triangle Park, NC. (NTIS No. PB 93&hyph;226769) 15 RATIO = X NEW / X OLD The proposed algorithm is equivalent to that in PAL and FDM and is more efficient than either of these algorithms. Based on comparisons with wind tunnel data, the proposed algorithm provides a more realistic characterization of the magnitude of impacts at receptors located within and nearby the area than that currently in ISC2, and gives comparable results to the FDM convergent algorithm when modeled based on the same assumptions for release height, mixing height, and dispersion parameters. Furthermore, these findings confirm that the currently used area source algorithm in ISC2 is an approximation that routinely under-estimates (and underrepresents) the actual ambient impact, especially for receptor locations within and near an area source. (2) Long-term algorithm: ISCLT2. The studies previously cited in footnotes 5, 6, and 7 have also indicated the deficiencies of the virtual point source algorithm used in ISCLT2. While it is computationally efficient, the virtual point source algorithm used in the original ISCLT2 yields estimates of limited accuracy for receptors located near the edges and corners of the area, a problem also seen with the original ISCST2. The algorithm cannot predict the area source impact for receptors located inside the source itself, and does not adequately handle effects of complex source-receptor geometry. Thus, a new area source algorithm for the ISCLT2, based on the numerical integration algorithm described above, was developed and evaluated. 16 Detailed performance tests, statistical analyses and sensitivity analyses were completed to assure the reliability and reasonableness of the modeling results. Using idealized meteorological conditions, the new algorithm yields very good comparison results when compared with the newly developed ISCST2 area source algorithm. For realistic meteorological data, the differences between ground level concentration values simulated with the new ISCLT2 algorithm and with the new ISCST2 counterpart are within about 10% for a typical source. The differences between the long-term and short-term algorithms using actual meteorological data are because ISCLT2 uses a meteorological frequency distribution to represent the meteorological conditions, and does not contain precise hour-to-hour information on specific combinations of wind speed, wind direction, stability class and mixing height that typically control the design values for the short-term model. Furthermore, sensitivity analyses show that the current ISCLT2 area source algorithm, based on the virtual source approach, routinely underestimates (and underrepresents) the actual maximum concentration impacts by a factor of 2 to 4, especially when the receptors are located inside or near the source. 16 Environmental Protection Agency, 1992. Development and Evaluation of a Revised Area Source Algorithm for the Industrial Source Complex Long Term Model. EPA Publication No. EPA&hyph;454/R&hyph;92&hyph;016. U.S. Environmental Protection Agency, Research Triangle Park, NC. (NTIS No. PB 93&hyph;226777) B. Dry Deposition Algorithm Deposition phenomena can be conceptualized in a two by two matrix, with a wet/dry dichotomy on one side and a particle/gas dichotomy on the other. Each of the four cells can then be further subdivided into simple and complex terrain components. Today's action proposes to replace the plume depletion and dry deposition algorithm 17 in the Industrial Source Complex model (ISC2) with a new algorithm that estimates the amount of material depleted from the plume as a combination of processes involving atmospheric turbulence and gravitational settling. This proposal embodies the simple terrain component of one cell in the conceptual matrix: dry deposition applied to particles. It is proposed that the new algorithm be implemented to treat dry deposition in rolling terrain, which is not possible in the current versions of ISC2. Future efforts may be directed at better characterizing gaseous and wet deposition in simple and complex. 17 ``User Instructions for the Draft Deposition Models DEPST and DEPLT'' (March 1994) have been uploaded to the SCRAM BBS. (Docket No. A&hyph;92&hyph;65; II&hyph;A&hyph;5). The dry deposition algorithm currently used in ISC2 is applicable to large particles (i.e., those with diameters greater than ~ ¢ 20μm) for which deposition is dominated by gravitational settling. In 1993, EPA initiated a study to evaluate the performance of alternative deposition algorithms. A review of the technical literature identified four core algorithms and six variants suitable for testing, producing a field of ten algorithm candidates. Estimates based on these algorithms were compared with observations from several data bases. Objective statistical procedures 18 were used to measure model performance. The main feature of this approach is to compute normalized statistical measures of the fractional bias between observed and predicted values. 18 Environmental Protection Agency, 1992. Protocol for Determining the Best Performing Model. EPA Publication No. EPA&hyph;454/R&hyph;92&hyph;025. U.S. Environmental Protection Agency, Research Triangle Park, NC. (NTIS No. PB 93&hyph;226082) Based on the evaluation, 19 the performance among the three top-ranked dry deposition algorithms was statistically indistinguishable. The three top-ranked models were UAM 2, CARB 3 and ADOM 1. The UAM 2 and CARB 3 algorithms represent a hybrid variant of their respective core algorithms with an added Leaf Area Index (LAI) 20 adjustment. ADOM 1, currently employed in the Acid Deposition and Oxidant Model, is a core algorithm (does not include a LAI adjustment). The results of the evaluation suggest that the reflection coefficient method used in ISC2 does not perform well for particle sizes less than 20μm in diameter. 19 Environmental Protection Agency, 1994. Development and Testing of a Dry Deposition Algorithm (Revised). EPA Publication No. EPA&hyph;454/R&hyph;94&hyph;015. U.S. Environmental Protection Agency, Research Triangle Park, NC. (NTIS No. PB 94&hyph;183100) Note: This report replaces one previously completed because an error was discovered after the earlier report was issued. The following memorandum details the nature of the error and documents the validity of the newer report. Memorandum from Jawad S. Touma et al. to Joseph A. Tikvart: Comments on the report ``Development and Testing of a Dry Deposition Algorithm (Revised)'', 6 May 1994 (3pp. w/5 attachments) (Dockets No. A&hyph;92&hyph;65; II&hyph;E&hyph;1) 20 The LAI is a ration of leaf surface area divided by ground surface area and can be estimated from land use type and season.
