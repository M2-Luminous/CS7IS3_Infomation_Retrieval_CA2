FBIS4-20490 "jpcst006___94017" JPRS-CST-94-006 JPRS Science & Technology China 11 April 1994 Computers Architecture of Fully Connected Scalable Parallel Architecture of Fully Connected Scalable Parallel Accelerator 94P60178A Beijing JISUANJI XUEBAO [CHINESE JOURNAL OF COMPUTERS] in Chinese Vol 17 No 3, Mar 94 pp 204-211 94P60178A Beijing JISUANJI XUEBAO [CHINESE JOURNAL OF COMPUTERS] Chinese CSO [Article by Dong Yingfei [5516 6601 7378], Wang Dingxing [3769 7844 5281], et al. of the Dept. of Computer Science and Technology, Qinghua University, Beijing 100084: ``Architectural Design of a Fully Connected Scalable Parallel Accelerator,'' supported by grant from State 863 High-Tech Program; MS received 11 May 93] [Abstract] Current artificial intelligence (AI) computer systems research platforms fall into two categories: (1) special-purpose systems (Japan's Fifth-Generation Computers, Britain's ALICE computer(s), the ESPRIT program's Flagship computer(s), and the U.S.'s Explorer computer(s)) supporting symbolic computations and expanding AI applied research and (2) general-purpose parallel computer systems or computing-engine-type parallel accelerators (the U.S.'s hypercube systems and Britain's ZAPP system) designed both for high-speed numerical computations in parallel C and parallel Fortran programs and for supporting symbolic computations through a variety of AI-language compiling systems. As an example of the latter category, the authors introduce their fully connected scalable parallel accelerator, a computing-engine-type scalable multiComputer (smC) system, and discuss its architecture. The system's processing elements (PEs) are the INMOS Company's IMS T9000 Transputer, a high-performance 32-bit CMOS RISC microprocessor system with built-in Virtual Channel Processor (VCP) flow control. The T9000's interconnection network consists of IMS C104 programmable 32-input/32-output packet-routing switches incorporating wormhole routing. All of the smC's PEs are fully connected logically. This parallel accelerator supports multiusers and multitasking efficiently and is easily scalable. The basic (32-PE) smC system has a peak operating speed of 5 GOPS (billion operations per second) and 1 GFLOPS (billion floating-point operations per second) (32-bit). Each PE consists of a T9000 Transputer with 8 MB or 16 MB local memory. The T9000's VCP segments the information into packets, with a format shown in Figure 1, not reproduced. Figure 2, not reproduced, shows the interconnection network for a single accelerator board (one-fourth of the basic four-board smC system), consisting of eight T9000 PEs and three C104 packet-routing switches. Figure 3, reproduced below, shows the interconnection network of the entire basic parallel accelerator. Figure 4, reproduced below, is a schematic of a 16-PE parallel accelerator (half of the basic smC system) showing connections with the system host(s), Sun SPARC10 workstation(s). Figures 5-7, not reproduced, show a schematic of the interconnection network for a 16-PE system, the same for a 64-PE system, and a schematic of the interface circuitry, respectively. There are no tables. Figure 3. Interconnection Network of Entire Basic (32-PE) Figure 4. Schematic of 16-PE Parallel Accelerator (Half of References 1. Technical Appraisal Report for Parallel Graph Reduction Intelligent Workstation [in Chinese], Computer Dept., Qinghua University, April 1992 [see JPRS-CST-92-012, 18 Jun 92 p 53]. 2. The T9000 TRANSPUTER Products Overview Manual, INMOS Doc. # 72 TRN 228, Order Code: DBTRANSPST/1, 1991. 3. Dally, W. J., Seitz, C. L., ``The Torus Routing Chip,'' JOURNAL OF DISTRIBUTED COMPUTING, 1986, 1 (3): 187-196. 4. Felperin, S. A., Gravano, L., et al., ``Routing Techniques for Massively Parallel Communications,'' PROC. OF THE IEEE, 1991, 79 (4): 488-503. 5. Dally, W. J., et al., ``The J-Machine: a Fine-Grain Concurrent Computer,'' in: Proc. of the IFIP Congress, 1989, 1147-1153.
